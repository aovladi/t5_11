{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c1b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9e8d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0.dev20220426+cu113'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac74d485",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/__init__.py'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b71808eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.defaults import train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a9d0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = train_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd2d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba51b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/t5-v1_1-xl\"\n",
    "tokenizer_name = \"t5-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab16e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead,AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5573542f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"demo_xl_0061vl.pt\")) #(\"t5-smalltrain_acc4.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5575cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7953f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets_grammar as dg\n",
    "from config.defaults import train_config\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "506304cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = train_config()\n",
    "torch.cuda.set_device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45b36fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-d7ffb4b425f4541a\n",
      "Reusing dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-d7ffb4b425f4541a/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f869bf233c4c17b8b8617f3cd96c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2988\n",
      "using dataset datasets_grammar/grammar_validation.csv\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dg.get_dataset(tokenizer, cfg.dataset_test, 512, 512, True)\n",
    "print(len(test_dataset))\n",
    "print(f\"using dataset {cfg.dataset_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22eda70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_step(model, batch):\n",
    "    #print(batch.keys())\n",
    "    curr_loss = torch.zeros(3)#.to(\"cuda:0\")\n",
    "    for key in batch.keys():\n",
    "        #print(f\"batch key = {key}\")\n",
    "        batch[key] = batch[key].to(\"cuda:0\")\n",
    "        \n",
    "    output = model(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            labels=batch[\"target_ids\"],\n",
    "        )\n",
    "    curr_loss[0] += output[\"loss\"].item()  # sum up batch loss\n",
    "    curr_loss[1] +=len(batch)\n",
    "        #print(curr_loss)\n",
    "        #pred = output.logits.argmax(\n",
    "         #       dim=1, keepdim=True\n",
    "         #   )  # get the index of the max log-probability\n",
    "        #print(pred)\n",
    "        #curr_loss[1] += pred.eq(batch[\"target_ids\"].view_as(pred)).sum().item()\n",
    "        #curr_loss[2] += len(batch)\n",
    "        #print(output)\n",
    "        #loss = 0\n",
    "    #loss = model(**data)\n",
    "    return curr_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbd8f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = torch.zeros(3)\n",
    "    for batch_index, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            loss = validate_one_step(model, data)\n",
    "        total_loss += loss\n",
    "        \n",
    "        print(total_loss[0]/total_loss[1])\n",
    "        if batch_index > 4:\n",
    "            break\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6646142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(model, dataloader, device):\n",
    "    ddp_loss = torch.zeros(3).to(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            for key in batch.keys():\n",
    "                batch[key] = batch[key].to(\"cuda:0\")\n",
    "            output = model(\n",
    "                input_ids=batch[\"source_ids\"],\n",
    "                attention_mask=batch[\"source_mask\"],\n",
    "                labels=batch[\"target_ids\"],\n",
    "            )\n",
    "            ddp_loss[0] += output[\"loss\"].item()  # sum up batch loss\n",
    "            ddp_loss[1] += len(batch)\n",
    "            #ddp_loss[0] += \n",
    "            #pred = output.logits.argmax(\n",
    "             #   dim=1, keepdim=True\n",
    "            #)  # get the index of the max log-probability\n",
    "            #print(f\"pred = {pred.shape}\\n{pred}\")\n",
    "            #ddp_loss[1] += pred.eq(batch[\"target_ids\"].view_as(pred)).sum().item()\n",
    "            \n",
    "\n",
    "    test_loss = ddp_loss[0] / ddp_loss[1]\n",
    "    print(f\"Total test loss: {test_loss}\")\n",
    "    return test_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a3ab31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42254b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.set_device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e557bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test loss: 3.035662889480591\n"
     ]
    }
   ],
   "source": [
    "test_loss = test_one_epoch(model,test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1256911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0357, device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daaeedb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4083)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss[0]/test_loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21154030",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"The cherry blossoms was so pretty\"\n",
    "test2 = \"Our dogs is running in the park.\"\n",
    "test3 = \"Their the ones who made a mistake.\"\n",
    "test4 = \"Its cold outside today.\"\n",
    "test5 = \"The baby was held by its mother.\"\n",
    "test6 = \"The book on AI really effected me.\"\n",
    "test7= \"The children love eating, coloring, and to play with their toys.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2eb715dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test #\"I is reading about AI articles \"\n",
    "inputs = tokenizer(\"grammar:\"+text, truncation=True, return_tensors='pt')\n",
    "#inputs.to(\"cuda:0\")\n",
    "\n",
    "output = model.generate(inputs['input_ids'], num_beams=5, max_length=512, early_stopping=True)\n",
    "correction=tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "result=(\"\".join(correction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "191725dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correction(model, tokenizer, text):\n",
    "    inputs = tokenizer(\"grammar:\"+text, truncation=True, return_tensors='pt')\n",
    "    #inputs.to(\"cuda:0\")\n",
    "\n",
    "    output = model.generate(inputs['input_ids'], num_beams=5, max_length=512, early_stopping=True)\n",
    "    correction=tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    result=(\"\".join(correction))\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c992ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_string(input_string, model, tokenizer):\n",
    "    print(fore.LIGHTBLUE_EX +f\"{input_string}\")\n",
    "    result = get_correction(model, tokenizer, input_string)\n",
    "    print(fore.GREEN+f\"{result}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea2d2b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: The cherry blossoms was so pretty\n",
      "\n",
      "corrected: The cherry blossoms were so pretty.\n"
     ]
    }
   ],
   "source": [
    "print(f\"input: {text}\\n\")\n",
    "print(f\"corrected: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a74b7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "test11=\"Every girl must bring their own lunch.\"\n",
    "test12= \"Its a cold day for October.\"\n",
    "test13 = \"These recipes is good for beginning chefs.\"\n",
    "test14 = \"At eight years old, my father gave me a pony for Christmas.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c37687d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test15 = \"Sharon stayed home from school the other day. Because she was sick.\"\n",
    "test16 = \"Jim went to the store and Ella went with him.\"\n",
    "test17 = \"The dad found the boy, and he was happy.”\"\n",
    "test18 = \"There father went to school there.\"\n",
    "test19=\"The rain had a good affect on the farmer’s field.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4ac16de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test20=\"The dogs dish was full of bone’s.\"\n",
    "test21=\"I am doing good in math.\"\n",
    "test22=\"Susan gave me a real nice bouquet of flowers.\"\n",
    "test23=\"There were less cans on the shelves than there were yesterday.\"\n",
    "test24=\"When you get done with that lab report, can you send it to Bill and I?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10be8847",
   "metadata": {},
   "outputs": [],
   "source": [
    "test25=\"We need to get our sale’s numbers up.\"\n",
    "test26=\"He starts work everyday at 8 a.m.\"\n",
    "test27 = \"The marketing manager told Riley and I to talk with her.\"\n",
    "test28 = \"Less than 50 people showed up for the presentation.\"\n",
    "test29=\"I could just lay down and go to sleep.\"\n",
    "test30=\"The people that reach their sales target will get a reward.\"\n",
    "test31=\"That presentation was better then the first one. \"\n",
    "test32=\"Your my favorite supervisor.\"\n",
    "test33 = \"There going to they’re office over their.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d474ecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mThese recipes is good for beginning chefs.\n",
      "\u001b[32mThese recipes are good for beginning chefs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_string(test13, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test, test6, test7, test15 (sentence fragments), test19(affect effect), test13, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d0ca95ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a824e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from colorama import Fore as fore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6f8a1668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mhello\n"
     ]
    }
   ],
   "source": [
    "print(fore.BLUE+\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9bc99fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mThe cherry blossoms was so pretty\n",
      "\u001b[32mThe cherry blossoms were so pretty.\n",
      "\n",
      "\u001b[94mThe book on AI really effected me.\n",
      "\u001b[32mThe book on AI really affected me.\n",
      "\n",
      "\u001b[94mThe children love eating, coloring, and to play with their toys.\n",
      "\u001b[32mChildren love eating, coloring, and playing with their toys.\n",
      "\n",
      "\u001b[94mSharon stayed home from school the other day. Because she was sick.\n",
      "\u001b[32mSharon stayed home from school the other day because she was sick.\n",
      "\n",
      "\u001b[94mThe rain had a good affect on the farmer’s field.\n",
      "\u001b[32mThe rain had a good effect on the farmer’s field.\n",
      "\n",
      "\u001b[94mThese recipes is good for beginning chefs.\n",
      "\u001b[32mThese recipes are good for beginning chefs.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = [test, test6, test7, test15, test19, test13]\n",
    "outputs = []\n",
    "\n",
    "for item in inputs:\n",
    "    res = eval_string(item, model, tokenizer)\n",
    "    outputs.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "973f7ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cherry blossoms was so pretty\n",
      "None\n",
      "\n",
      "The book on AI really effected me.\n",
      "None\n",
      "\n",
      "The children love eating, coloring, and to play with their toys.\n",
      "None\n",
      "\n",
      "Sharon stayed home from school the other day. Because she was sick.\n",
      "None\n",
      "\n",
      "The rain had a good affect on the farmer’s field.\n",
      "None\n",
      "\n",
      "These recipes is good for beginning chefs.\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for pre, post in zip(inputs, outputs):\n",
    "    print(pre)\n",
    "    print(post)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ababc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p38)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
